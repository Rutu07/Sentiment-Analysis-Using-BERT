{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7856909ae8644f18c997b333df5d335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2291e12a5344468af9e6438cdb98eb7",
              "IPY_MODEL_b972d487ea4c471a9a2f9f95b337f116",
              "IPY_MODEL_c59c9c5a34f64658bf4e3b2d998119e1"
            ],
            "layout": "IPY_MODEL_93611af36eea42e6a13e12c6967e6342"
          }
        },
        "f2291e12a5344468af9e6438cdb98eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e283680d3f134a4690584d323460b951",
            "placeholder": "​",
            "style": "IPY_MODEL_afd824416bf44bc29bd8df5cc080438c",
            "value": "100%"
          }
        },
        "b972d487ea4c471a9a2f9f95b337f116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f26fb55f2d94a16910c1928ccff1dae",
            "max": 14640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d384c7ca43704e1bba5fe4b73ef672ce",
            "value": 14640
          }
        },
        "c59c9c5a34f64658bf4e3b2d998119e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066b94ec744c4bf0bc9bf60e0620af39",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6b89712f7541f2ad5ceab8870595d0",
            "value": " 14640/14640 [00:04&lt;00:00, 6186.10it/s]"
          }
        },
        "93611af36eea42e6a13e12c6967e6342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e283680d3f134a4690584d323460b951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd824416bf44bc29bd8df5cc080438c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f26fb55f2d94a16910c1928ccff1dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d384c7ca43704e1bba5fe4b73ef672ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "066b94ec744c4bf0bc9bf60e0620af39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6b89712f7541f2ad5ceab8870595d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rutu07/Sentiment-Analysis-Using-BERT/blob/main/Airline_Tweets_Sentiment_Analysis_Using_BERT(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "i6e_CLkpoTUr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1Aq1koswNtu"
      },
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPU (Graphics Processing Unit) enable paralle processing of complex tasks. Lot of computing power is required to train Neural Networks on thousands/millions of records and GPUs provide this computing power. \n",
        "- Traditional CPUs are capable of completing task in sequential manner along with their multi-cores, however GPUs process many parts of data simultaneously."
      ],
      "metadata": {
        "id": "6Rg9VU3HwOVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_colwidth',200)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#library for progress bar\n",
        "from tqdm import notebook\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "qZYw3GFgvHyl"
      },
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMazwWryxoC0"
      },
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime->Change RunTIme-> Select GPU in Hardware Accelrator\n"
      ],
      "metadata": {
        "id": "cWsFU4NBxoXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if GPU is available. \n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device('cuda')"
      ],
      "metadata": {
        "id": "0_k00AxdxiKo"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)\n",
        "torch.cuda.get_device_name(0)\n",
        "# Current GPU is Tesla T4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oXQhWDNtvIO3",
        "outputId": "55c17fdb-2251-40f4-f6f0-149356859975"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqVBhDYCyOro"
      },
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Installing Hugging Face's Transformers Library\n",
        "- Hugging face is one of the most popular NLP library and provides a wide range of transformer-based models such as BERT, GPT-2, Roberta, and so on.\n"
      ],
      "metadata": {
        "id": "02SHj9i2yPSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpbMWwkgvIs0",
        "outputId": "2a6c9060-2314-4858-ea6c-f355c9f1d658"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLTf0t1Y1gQ5"
      },
      "execution_count": 427,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Installing BertModel "
      ],
      "metadata": {
        "id": "mKSoA0la14_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT uncased: This model was trained on lower case text data. Other types of pre-trained models, can be found at https://huggingface.co/models\n"
      ],
      "metadata": {
        "id": "MpFqUGlO0GBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertModel\n",
        "# Import BERT pretrained module\n",
        "from transformers import BertModel\n",
        "\n",
        "#Download uncased bert base model\n",
        "bert=BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLtv1XgKvI3z",
        "outputId": "ce91865f-169f-4bf5-8652-b2755e29a8f7"
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print BERT arcitecture\n",
        "print(bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3isN0Fr01bc",
        "outputId": "6adde272-baac-4f39-9639-95d87de8a41a"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Importing BERT tokenizer\n",
        "It tencodes text into positional encodings combined with word(contextual) embeddings. The tokenizer version present in transformers library is the fast version."
      ],
      "metadata": {
        "id": "XiccmS2N2BAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast\n",
        "# importing BERT tokenizer \n",
        "tokenizer=BertTokenizerFast.from_pretrained('bert-base-uncased',do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "lcel2F6Q1Dk_"
      },
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps occuring in Input Encoding**\n",
        "\n",
        "1. Tokenization\n",
        "2. Special Tokens\n",
        "  * Prepending [CLS] token at the start of the sequence\n",
        "  * Appneding [SEP] token at the end of the seqence\n",
        "3. Pad sequences\n",
        "4. Convert tokens into integers(vector embeddings)\n",
        "5. Create attention masks to indicate non padded elements.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KPYFKIN-7o7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='Jim Henson was a puppeteer'\n",
        "sentence_id=tokenizer.encode(text,\n",
        "                             # add special character tokens\n",
        "                             add_special_tokens=True,\n",
        "                             # Specifying maximum length for any input sequences\n",
        "                             max_length=10,\n",
        "                             # if exceeeding 10, then it will be truncated, if <10, then it will be padded.\n",
        "                             truncation=True,\n",
        "                             # add pad tokens to the right side of the sequence\n",
        "                             pad_to_max_length='right'\n",
        "                             )\n",
        "print(\"Integer Sequence:{}\".format(sentence_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK0Tes6Z1D5V",
        "outputId": "5e7efa28-45d5-4cfa-a5e3-f0c449a50822"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence:[101, 3958, 27227, 2001, 1037, 13997, 11510, 102, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [CLS] is represented by 101 where as [SEP] is represented by 102. Two zeros at the end represent padded elements to have a seuqnce of length 10."
      ],
      "metadata": {
        "id": "6QrcKfrx9v1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting integers back to text\n",
        "print(\"Tokenizer Text: \",tokenizer.convert_ids_to_tokens(sentence_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn5Zok3N1ESU",
        "outputId": "d1933506-35d6-498f-8b3a-959d4343df7a"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Text:  ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note that puppeteer was not a part of Bert tokenizer vocabulary while training. It doesn't have any word embedding for word puppeteer. Hence it was split into known part 'puppet' and unknown part '##eer'. The tokenizer has embeddings for both the tokens. ## represents that the token is a sub word. This is how BERT tokenizer handles unkwown words.\n",
        "\n",
        "- Using tokenizer.decode(), this can be decoded back into original sentence"
      ],
      "metadata": {
        "id": "T5IwrfCt-LLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded=tokenizer.decode(sentence_id)\n",
        "print('Decoded String:{}'.format(decoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE5R93bd1Ed-",
        "outputId": "9f1fab29-003d-4acf-a459-02dd2fc8fb9e"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded String:[CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Masking needs to be done to avoid performing attention on padding token indices.\n",
        "- mask value=1 for tokens and 0 for unmasked tokens"
      ],
      "metadata": {
        "id": "9Uws_ULn_OGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att_mask=[int(tok>0) for tok in sentence_id]\n",
        "print(att_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azy7xAEC_LoF",
        "outputId": "d654688d-51d4-42fb-ca30-f2e5be7b1bed"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding Input and Output of BERT Tokenizer**\n"
      ],
      "metadata": {
        "id": "tI12evHX_zhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To understand unsqueeze() and squeeze() function: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n"
      ],
      "metadata": {
        "id": "WseHlEeXCuLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert lists to tensors\n",
        "# torch.tensor creates a tensor of given data\n",
        "sent_id=torch.tensor(sentence_id)\n",
        "attn_mask=torch.tensor(att_mask)\n",
        "print('Shape of sentence_id before reshaping is: {}'.format(sent_id.shape))\n",
        "print('Shape of sentence_id before reshaping is: {}'.format(attn_mask.shape))\n",
        "print('\\n')\n",
        "# reshaping tensor in form of batch,text length\n",
        "sent_id=sent_id.unsqueeze(0)\n",
        "attn_mask=attn_mask.unsqueeze(0)\n",
        "print('Shape of sentence_id after reshaping is: {}'.format(sent_id.shape))\n",
        "print('Shape of sentence_id after reshaping is: {}'.format(attn_mask.shape))\n",
        "print('\\n')\n",
        "# reshaped tensor\n",
        "print(sent_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-I52Khv_6jX",
        "outputId": "8dd197df-3b01-447a-ec4d-0b8447c95ea7"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of sentence_id before reshaping is: torch.Size([10])\n",
            "Shape of sentence_id before reshaping is: torch.Size([10])\n",
            "\n",
            "\n",
            "Shape of sentence_id after reshaping is: torch.Size([1, 10])\n",
            "Shape of sentence_id after reshaping is: torch.Size([1, 10])\n",
            "\n",
            "\n",
            "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we can see that list of integers has beem converted into pytorch tensor of dimension (1,10)"
      ],
      "metadata": {
        "id": "M1yRfLXRDzAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# passing integer sequence and attention mask tensor to BERT model\n",
        "outputs=bert(sent_id,attention_mask=attn_mask)\n"
      ],
      "metadata": {
        "id": "nHMUs9atBm-3"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpacking the output of BERT model\n",
        "\n",
        "# all_hidden_states is a collection of all the output vectors/ hidden states (of encoder) at each timestamps or position of the BERT model\n",
        "all_hidden_states=outputs[0]\n",
        "\n",
        "print(all_hidden_states.shape)\n",
        "print(all_hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gjJ-7X4BnO6",
        "outputId": "50b170cc-e6f4-43d2-ed96-627677a47d2d"
      },
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 768])\n",
            "tensor([[[-0.2531,  0.2038, -0.3862,  ..., -0.3034,  0.6197,  0.2373],\n",
            "         [-0.2323, -0.0044, -0.5479,  ...,  0.0765,  0.8122, -0.4710],\n",
            "         [ 0.2590,  0.7140, -0.5438,  ..., -0.3774,  0.9987,  0.5400],\n",
            "         ...,\n",
            "         [ 0.7873,  0.3299, -0.0351,  ...,  0.2932, -0.5141,  0.0308],\n",
            "         [-0.5547, -0.3669, -0.1106,  ...,  0.2593,  0.5321, -0.3871],\n",
            "         [-0.5461, -0.2414, -0.2111,  ...,  0.3100,  0.5863, -0.3467]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 because we have only one senetence(sequence)\n",
        "- 10 because we have maximum of 10 words in each sequence. For shorter sentences, 0 are padded at right side.\n",
        "- 768 is the default dim of BERT output vector where every word out of 10 words is represented into a vector of 768 columns"
      ],
      "metadata": {
        "id": "yQccq9DOEe22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this output contains output vector against the CLS token only (at the first position of BERT model)\n",
        "# this output vector encodes the entire input sequence \n",
        "\n",
        "cls_hidden_state=outputs[1]\n",
        " \n",
        "print(cls_hidden_state.shape)\n",
        "print(cls_hidden_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x7ck6KSEc19",
        "outputId": "d0a9d023-a490-4331-a8ad-8dc3f1d561bb"
      },
      "execution_count": 438,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 768])\n",
            "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
            "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
            "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
            "          0.3924,  0.6864, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
            "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
            "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
            "         -0.8711,  0.0508,  0.0505, -0.1634,  0.1716,  0.4363,  0.4330, -0.0333,\n",
            "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
            "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
            "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
            "         -0.0400,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
            "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
            "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
            "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
            "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
            "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
            "         -0.1697, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
            "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
            "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
            "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
            "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
            "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2164, -0.9851, -0.4444,  0.5759,\n",
            "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
            "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
            "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2187,  0.5282, -0.3149, -0.4375,\n",
            "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
            "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
            "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
            "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
            "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
            "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
            "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
            "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
            "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
            "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
            "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
            "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
            "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
            "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
            "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
            "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
            "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
            "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
            "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
            "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
            "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
            "          0.9268, -0.4225, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
            "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
            "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
            "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
            "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
            "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
            "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
            "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
            "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
            "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
            "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
            "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
            "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
            "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
            "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
            "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
            "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
            "         -0.9936, -0.2000, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
            "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
            "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
            "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
            "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
            "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1413,\n",
            "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
            "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
            "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
            "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
            "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
            "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
            "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
            "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
            "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0724,\n",
            "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
            "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
            "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
            "          0.3962, -0.5013, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
            "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
            "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
            "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
            "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
            "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
            "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
            "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
            "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
            "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
            "          0.1236, -0.3705, -0.3959, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
            "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
            "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
            "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
            "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Data Preparation\n",
        "#### 5.1 Loading dataset and selecting important columns\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z-8UUqwQIxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'Airline_Tweets-200904-165552.zip'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BJmyCbbVZHn",
        "outputId": "5baf51f7-3985-4f8c-ce49-2524f7ff5fc4"
      },
      "execution_count": 439,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Airline_Tweets-200904-165552.zip\n",
            "replace Tweets.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Tweets.csv              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Tweets.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "jiowjFcGFqSK",
        "outputId": "c1bc089b-cd49-4c4f-a69a-9714ba8adfb6"
      },
      "execution_count": 440,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                                                                                             text  \\\n",
              "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
              "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
              "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
              "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
              "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
              "\n",
              "  tweet_coord              tweet_created tweet_location  \\\n",
              "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
              "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
              "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
              "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
              "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
              "\n",
              "                user_timezone  \n",
              "0  Eastern Time (US & Canada)  \n",
              "1  Pacific Time (US & Canada)  \n",
              "2  Central Time (US & Canada)  \n",
              "3  Pacific Time (US & Canada)  \n",
              "4  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-199c4841-c2d6-4f96-8384-288bfcb385c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-199c4841-c2d6-4f96-8384-288bfcb385c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-199c4841-c2d6-4f96-8384-288bfcb385c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-199c4841-c2d6-4f96-8384-288bfcb385c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhCingpyFqeB",
        "outputId": "4581e957-d701-48e6-d250-1877f77ee4ba"
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 441
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Features of our interest are label column and text column"
      ],
      "metadata": {
        "id": "r3uuTSlSU6pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8EZQc9kU512",
        "outputId": "b17e255c-c669-4e35-a97b-523ff3224a40"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6520                                           @SouthwestAir You officially have the worst customer service of any airline I've ever dealt with. #southwestairlines #poor\n",
              "8851                             @JetBlue I know where you guys jet! LOL, but if you love me so much, help a brother out :) Hot weather, great nightlife, 2-3 hour flight\n",
              "6927     @JetBlue flight for tomorrow morning Cancelled Flighted &amp; can't seem to rebook me. They can't even get me a seat. No clear answer on why Cancelled Flighted.\n",
              "13263                                                                                                         @AmericanAir SJC-&gt;LAX. After the fourth time, I gave up!\n",
              "3587                                                                                           @united &amp; I've been hung up on twice by your staff. So upset right now\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Distribution of Tweets (label)\n"
      ],
      "metadata": {
        "id": "B56ebuSLV4tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['airline_sentiment'].value_counts())\n",
        "print(df['airline_sentiment'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S68Qc7xaU5-i",
        "outputId": "43fe63fd-1b02-4bf1-ec09-b7e5d82fddf2"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    9178\n",
            "neutral     3099\n",
            "positive    2363\n",
            "Name: airline_sentiment, dtype: int64\n",
            "negative    0.626913\n",
            "neutral     0.211680\n",
            "positive    0.161407\n",
            "Name: airline_sentiment, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sabing value counts to a list\n",
        "class_counts=df['airline_sentiment'].value_counts().to_list()"
      ],
      "metadata": {
        "id": "rSCfceNCWF7p"
      },
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Text cleaning\n",
        "- Removing twitter usernames\n",
        "- Removing links (starting with https)\n",
        "- If needed removing hashtags"
      ],
      "metadata": {
        "id": "M5liMLrhWVu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  # converting text tolower case\n",
        "  text=text.lower()\n",
        "  # remove user mentions\n",
        "  text=re.sub(r'@[A-Za-z0-9]+','',text)\n",
        "  # remove hashtags if needed keep for now\n",
        "  #text=re.sub(r'#[A-Za-z0-9]+','',text)\n",
        "\n",
        "  # remove links\n",
        "  text=re.sub(r'http\\S+','',text)\n",
        "\n",
        "  # Split tokens so that extra spaces which were added due to above substitution are removed\n",
        "  tokens=text.split()\n",
        "\n",
        "  # join tokens by space\n",
        "  return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "_hzAuGhWWOxo"
      },
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using apply function to apply this preprocess function on each row of the text column\n",
        "df['cleaned_text']=df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "6ro0nCFFWO4Z"
      },
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()[['airline_sentiment','text','cleaned_text']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "ao3KcY3IXh8i",
        "outputId": "3b618277-28c4-4295-c9dd-387a9dc163ef"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  airline_sentiment  \\\n",
              "0           neutral   \n",
              "1          positive   \n",
              "2           neutral   \n",
              "3          negative   \n",
              "4          negative   \n",
              "\n",
              "                                                                                                                             text  \\\n",
              "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
              "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
              "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
              "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
              "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
              "\n",
              "                                                                                                      cleaned_text  \n",
              "0                                                                                                       what said.  \n",
              "1                                                        plus you've added commercials to the experience... tacky.  \n",
              "2                                                         i didn't today... must mean i need to take another trip!  \n",
              "3  it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
              "4                                                                         and it's a really big bad thing about it  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bafe95b-057d-42e0-8ab8-168abe00a3af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>what said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>i didn't today... must mean i need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bafe95b-057d-42e0-8ab8-168abe00a3af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bafe95b-057d-42e0-8ab8-168abe00a3af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bafe95b-057d-42e0-8ab8-168abe00a3af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving cleaned text and labels to variables\n",
        "text=df['cleaned_text'].values\n",
        "labels=df['airline_sentiment'].values"
      ],
      "metadata": {
        "id": "WQma0Wu3XupG"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(text))\n",
        "print(type(labels))\n",
        "print(text.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wSZ7dptXuiL",
        "outputId": "840da4e1-5106-4937-82c0-f2aa4f85f8e4"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(14640,)\n",
            "(14640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[50:55]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue1SY1WpYDtg",
        "outputId": "3ad88b18-62f5-4eac-8a35-0c8ce3674c68"
      },
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['is flight 769 on it\\'s way? was supposed to take off 30 minutes ago. website still shows \"on time\" not \"in flight\". thanks.',\n",
              "       'julie andrews all the way though was very impressive! no to',\n",
              "       'wish you flew out of atlanta... soon?',\n",
              "       'julie andrews. hands down.',\n",
              "       'will flights be leaving dallas for la on february 24th?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 450
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[50:55]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYuvLxqdY60I",
        "outputId": "51c07307-ab77-4b53-c9ff-817e0c3df9b2"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'positive', 'neutral', 'neutral', 'neutral'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Preparing input and output data \n",
        "- **Preparing target input**\n"
      ],
      "metadata": {
        "id": "c0lMweSgYV5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using label encoder, convert textual labels (positive, negative, neutral) into numners\n",
        "le=LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a number\n",
        "labels=le.fit_transform(labels)"
      ],
      "metadata": {
        "id": "PVo5wi1DYVYY"
      },
      "execution_count": 452,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAeLM2U_XuXs",
        "outputId": "927d73fd-b8da-4034-a3f7-1de4ffbd35a1"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 453
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ1I_DzpZS0M",
        "outputId": "12d284b8-b3b4-4989-ba0f-a9e4b415e5a0"
      },
      "execution_count": 454,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVz9jb22J9C2",
        "outputId": "1d951169-0d13-4669-c02d-80bae7872819"
      },
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {},
          "execution_count": 455
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Visualize length of tweets\n"
      ],
      "metadata": {
        "id": "YXc7rBmLZci3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num=[len(i.split()) for i in text]\n",
        "plt.hist(num,bins=30)\n",
        "plt.title('Histogram: Length of sentences')\n",
        "plt.xlabel('Length of sentences')\n",
        "plt.ylabel('Count of sentences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "o8O_ueeqZYZp",
        "outputId": "bdb01d73-d37d-47b8-845a-eb8a006a366f"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count of sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 456
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It can be observed that most of the sentences (~95%) have length of 25 words. Hence, we select max_length as 25 for all the tweets in our dataset. \n",
        "- All the sequences will be paddded to 25.\n",
        "- How to decide?\n",
        "If you choose too big number, then most of the positions in your sequence will have padded tokens. So choose a number near to your max lenght of text sequence"
      ],
      "metadata": {
        "id": "JYONnhERZ8kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Preparing Textual Input**"
      ],
      "metadata": {
        "id": "g3oQrOYQcaEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=28 # This is a hyper parameter which can be tuned"
      ],
      "metadata": {
        "id": "RYJB3P-jZ6hD"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using bert tokenizer, convert text sequences into numerical vectors"
      ],
      "metadata": {
        "id": "fBR5wDuKcF9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to save integer sequence\n",
        "sent_id=[]\n",
        "\n",
        "# iterate over each tweet and encode it using bert tokenizer\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "  encoded_sent=tokenizer.encode(text[i],\n",
        "                                add_special_tokens=True,\n",
        "                                max_length= max_len,\n",
        "                                truncation=True,\n",
        "                                pad_to_max_length='right'\n",
        "                                )\n",
        "  \n",
        "  # save integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "a7856909ae8644f18c997b333df5d335",
            "f2291e12a5344468af9e6438cdb98eb7",
            "b972d487ea4c471a9a2f9f95b337f116",
            "c59c9c5a34f64658bf4e3b2d998119e1",
            "93611af36eea42e6a13e12c6967e6342",
            "e283680d3f134a4690584d323460b951",
            "afd824416bf44bc29bd8df5cc080438c",
            "9f26fb55f2d94a16910c1928ccff1dae",
            "d384c7ca43704e1bba5fe4b73ef672ce",
            "066b94ec744c4bf0bc9bf60e0620af39",
            "ae6b89712f7541f2ad5ceab8870595d0"
          ]
        },
        "id": "ODFQsKJuZ6pJ",
        "outputId": "47502736-cb97-4291-c067-f68e7f47f303"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14640 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7856909ae8644f18c997b333df5d335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h-Y1qCLbhJT",
        "outputId": "2a60b004-ab97-4f62-d10b-e43401280fc1"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what said.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_id[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbp5jAmjbc45",
        "outputId": "2fe13eda-8f2f-40ee-991c-e44ba5e94544"
      },
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 2054, 2056, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtZpwOB1KGk9",
        "outputId": "16ba6d5f-4a91-4674-b6cc-4430dc8c2497"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {},
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can see here that '.' i.e. full stop is represented by different number (1012). \n",
        "- 101 represents CLS token and 102 represents SEP token"
      ],
      "metadata": {
        "id": "SzWSIGQVuMjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create Attention masks"
      ],
      "metadata": {
        "id": "yJemoraWcvoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask=[]\n",
        "\n",
        "for sent in sent_id:\n",
        "  attn_mask=[int(token_id>0) for token_id in sent]\n",
        "  attention_mask.append(attn_mask)"
      ],
      "metadata": {
        "id": "dKc7plQVZ6wQ"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hZM8zZmJ36P",
        "outputId": "72690479-e392-43ce-ac6f-383d44dcd73f"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14640"
            ]
          },
          "metadata": {},
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Training and Validation Data"
      ],
      "metadata": {
        "id": "6rOwHCYbdN_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting input data\n",
        "train_inputs,validation_inputs, train_labels,validation_labels=train_test_split(sent_id,labels,random_state=2018, test_size=0.1,stratify=labels)\n",
        "# Splitting masks\n",
        "train_mask,validation_mask,_,_= train_test_split(attention_mask,labels,random_state=2018,test_size=0.1,stratify=labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "x7gnLpisFBIQ"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For both the labels and attention mask, keeping random_state=2018 same, ensures that same indices are randomly being picked up from both the lists.\n",
        "-stratify=label ensures the ratio of labels in original dataset is maintained in the train and validation set."
      ],
      "metadata": {
        "id": "-WTmrku8Gkul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7: Define Dataloaders"
      ],
      "metadata": {
        "id": "usgyOXquGkyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all inputs and labels into torch tensors which is the required datatype for the BERT model\n",
        "\n",
        "train_inputs=torch.tensor(train_inputs)\n",
        "train_labels=torch.tensor(train_labels)\n",
        "train_mask=torch.tensor(train_mask)\n",
        "\n",
        "validation_inputs=torch.tensor(validation_inputs)\n",
        "validation_labels=torch.tensor(validation_labels)\n",
        "validation_mask=torch.tensor(validation_mask)"
      ],
      "metadata": {
        "id": "dOFPWdq1dDpq"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In a dataset, we store indices and it's corresponding labels\n",
        "- Where as in Dataloaders, an iterator is wrapped aroound the dataset so that sampling can be performed easlily (by accessing indices of rows). With the help of iterator, it is easy to iterate through the batches and understand encoded sequences.\n",
        "- Basically Dataloader takes in dataset and sampler to return an iterable over dataset\n",
        "- The output of DataLoader is input batch, masks batch and labels batch.\n",
        "- batch_size is needed for training, and in order to fine-tune BERT on a specific task, the authors recommend a batch size of 16 or 32"
      ],
      "metadata": {
        "id": "cmrAwbK8Na-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QSnK2l7KQ_w",
        "outputId": "fd1d66b8-5664-4389-c9b4-f824f533d745"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2044,  1016,  ..., 22368,  1012,   102],\n",
              "        [  101,  1045,  2444,  ...,  2068,  1012,   102],\n",
              "        [  101,  1996,  2034,  ...,  1045,  2081,   102],\n",
              "        ...,\n",
              "        [  101,  2003,  2045,  ...,  1012,  1045,   102],\n",
              "        [  101,  2073,  1005,  ...,     0,     0,     0],\n",
              "        [  101,  1996,  2711,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size\n",
        "batch_size=64\n",
        "\n",
        "# Creating Tensor Dataset for training data\n",
        "train_data=TensorDataset(train_inputs,train_mask,train_labels)\n",
        "\n",
        "# Defining a random sampler during training\n",
        "train_sampler=RandomSampler(train_data)\n",
        "\n",
        "# Creating iterator using DataLoader. This iterator supports batching, customized data loading order\n",
        "train_dataloader=DataLoader(train_data,sampler=train_sampler,batch_size=batch_size )\n",
        "\n",
        "# Creating tensor dataset for validation data\n",
        "validation_data=TensorDataset(validation_inputs,validation_mask,validation_labels)\n",
        "\n",
        "# Defining a sequential sampler during validation, bcz there is no need to shuffle the data. We just need to validate\n",
        "validation_sampler=SequentialSampler(validation_data)\n",
        "\n",
        "# Create an iterator over validation dataset\n",
        "validation_dataloader=DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "jSetRnG8dDxP"
      },
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensor Dataset: It creates dataset by combining different tensors\n",
        "- DataLoader: Loads the dataset in the form of batchs\n",
        "- Random Sampler: Samples batches randomly from the data loader\n",
        "- Sequential Sampler: It samples the batches sequentially from the data loader"
      ],
      "metadata": {
        "id": "GaJtyl2PO89p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an iterator object\n",
        "iterator=iter(train_dataloader)\n",
        "\n",
        "# loads batch data\n",
        "sent_id,mask,target=iterator.__next__()"
      ],
      "metadata": {
        "id": "T0wc7v9xRO0V"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsOyCRPPRmwY",
        "outputId": "cc40a8ed-f4b1-4edf-f71b-a70726ed7537"
      },
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 469
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 32 is a batch size (32 text records) and 25 is the length of sequence"
      ],
      "metadata": {
        "id": "NhvjVaBsSQ3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr58fcWsRnRO",
        "outputId": "7bf34905-74ab-4e42-f117-e4a4a17c0f2a"
      },
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1045,  2123,  ...,  2340,  2572,   102],\n",
              "        [  101,  2003,  2045,  ...,  1012,  2053,   102],\n",
              "        [  101,  1996,  3042,  ..., 16649,  2043,   102],\n",
              "        ...,\n",
              "        [  101,  2023,  2003,  ...,  2006,  1037,   102],\n",
              "        [  101, 18356,  1998,  ...,  2017,  2069,   102],\n",
              "        [  101,  3462,  8014,  ...,  1055,  2026,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 470
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=bert(sent_id,attention_mask=mask)"
      ],
      "metadata": {
        "id": "Lu7GdnfXRnbg"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states=outputs[0]\n",
        "CLS_hidden_state=outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENs92ZMwRnl_",
        "outputId": "5132fcf6-0047-49fa-e167-73b4aeabe039"
      },
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([64, 28, 768])\n",
            "Shape of CLS Hidden State: torch.Size([64, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NeWy2vKQFmi",
        "outputId": "8766f238-ede1-403a-c5d9-6a86ade6e7aa"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 8: Fine-Tuning BERT"
      ],
      "metadata": {
        "id": "OH6x4-__TFB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The pretrained BERT model is trained on large amount of general corpus. Finetuning the pretrained model will help us capture domain specific features from our dataset.\n",
        "- Here, we will fine tune only head layer. i.e. Head Layer is the dense layer added on the top of the pre-trained bert model. This layer is used for classification tasks."
      ],
      "metadata": {
        "id": "rRahFehuS4M8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients: This step is freezes the parameters of BERT model, so that when we fine tune the model, the parameters of BERT model are not affected, only weights of head part are affected.\n",
        "\n"
      ],
      "metadata": {
        "id": "IQbCIa6cKaC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# turn off the gradient of all parameters\n",
        "\n",
        "for param in bert.parameters():\n",
        "  param.requires_grad=False"
      ],
      "metadata": {
        "id": "OsJg7W5zSyU2"
      },
      "execution_count": 474,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define Model Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "KXinhjd8LKtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Classifier is a sub class of nn.Module from pytorch\n",
        "class classifier(nn.Module):\n",
        "\n",
        "  # define the layers and wrappers used by model\n",
        "  def __init__(self,bert):\n",
        "    #Constructor. \n",
        "    super(classifier,self).__init__() #using super() which is a proxy instance of super class-nn.Module to access the __init__() method of nn.Module\n",
        "    # bert model\n",
        "    self.bert=bert\n",
        "\n",
        "    #dense layer 1\n",
        "    self.fc1=nn.Linear(768,512) # the output of BERT has 768 and 512 can be any hyperparameter which we can tune\n",
        "\n",
        "    #dense layer 2 (output layer)\n",
        "    self.fc2=nn.Linear(512,3)   # 3 because our class label has 3 categories\n",
        "\n",
        "    # droupout layer\n",
        "    self.dropout=nn.Dropout(0.1)\n",
        "\n",
        "    # relu activation function\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "    #softmax activation function\n",
        "    self.softmax=nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "  # Define the forward pass\n",
        "  def forward(self,sent_id,mask):\n",
        "\n",
        "    # pass the inputs to the model\n",
        "    all_hidden_states,cls_hidden_state=self.bert(sent_id,attention_mask,return_dict=False)\n",
        "\n",
        "    # pass CLS hidden state to dense layer\n",
        "    x=self.fc1(cls_hidden_state)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x=self.relu(x)\n",
        "\n",
        "    # Apply dropout\n",
        "    x=self.dropout(x)\n",
        "\n",
        "    # pass input to the output layer\n",
        "    x=self.fc2(x)\n",
        "\n",
        "    # apply softmax activation\n",
        "    x=self.softmax(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "OlL69BALLEzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "428f8363-13fd-4fa5-ec0e-c4cf7af2748a"
      },
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Classifier is a sub class of nn.Module from pytorch\\nclass classifier(nn.Module):\\n\\n  # define the layers and wrappers used by model\\n  def __init__(self,bert):\\n    #Constructor. \\n    super(classifier,self).__init__() #using super() which is a proxy instance of super class-nn.Module to access the __init__() method of nn.Module\\n    # bert model\\n    self.bert=bert\\n\\n    #dense layer 1\\n    self.fc1=nn.Linear(768,512) # the output of BERT has 768 and 512 can be any hyperparameter which we can tune\\n\\n    #dense layer 2 (output layer)\\n    self.fc2=nn.Linear(512,3)   # 3 because our class label has 3 categories\\n\\n    # droupout layer\\n    self.dropout=nn.Dropout(0.1)\\n\\n    # relu activation function\\n    self.relu=nn.ReLU()\\n\\n    #softmax activation function\\n    self.softmax=nn.LogSoftmax(dim=1)\\n\\n\\n  # Define the forward pass\\n  def forward(self,sent_id,mask):\\n\\n    # pass the inputs to the model\\n    all_hidden_states,cls_hidden_state=self.bert(sent_id,attention_mask,return_dict=False)\\n\\n    # pass CLS hidden state to dense layer\\n    x=self.fc1(cls_hidden_state)\\n\\n    # Apply ReLU activation function\\n    x=self.relu(x)\\n\\n    # Apply dropout\\n    x=self.dropout(x)\\n\\n    # pass input to the output layer\\n    x=self.fc2(x)\\n\\n    # apply softmax activation\\n    x=self.softmax(x)\\n\\n    return x\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 475
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert \n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "      \n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "6x6ZtgHIRmRH"
      },
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why do you need dropout?**\n",
        "- Dropout means randomly ignoring neurons during the training phase to reduce over fitting.\n",
        "- A fully connected neural network accumulates most of the parameters and as a result, neurons develop co-dependency amongst each other during training phase. This controls the individual power of each neuron and leads to voer-fitting of training data"
      ],
      "metadata": {
        "id": "3ft1pLyA6f69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model=classifier(bert)\n",
        "\n",
        "# push the model to GPU, if available\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "id": "FP1Qel3cLFJ6"
      },
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model arcitecture\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DDz8xaTLFQS",
        "outputId": "b0dc74c5-5940-4e5b-9959-f20b589b0946"
      },
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can see that fc1, fc2 are the 2 additional linear layers we've added to the BERT model\n"
      ],
      "metadata": {
        "id": "IKb3uSjqN0TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(sent_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MuTSm7yQb-7",
        "outputId": "2079566f-dc55-4b2d-d918-fa1aa8c4f015"
      },
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# push the tensors to GPU\n",
        "sent_id=sent_id.to(device)\n",
        "mask=mask.to(device)\n",
        "target=target.to(device)\n"
      ],
      "metadata": {
        "id": "rZoIke-BLFY7"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass inputs to the model\n",
        "outputs=model(sent_id,mask)"
      ],
      "metadata": {
        "id": "r9xx19zfOG5y"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The forward method is called from the __call__ function of nn.Module when we run the above line of code. \n",
        "- When the classifier class is instantiated, all the statements withi __init__() class are executed. i.e. constructor is executed.\n",
        "- When we run the classifier on input data, via model(sent_id, mask) the __call__ method is invoked.\n",
        "- The classifier class simply inherits the __call__ method of the nn.Module class and when we run classifier(input), the forward method is called."
      ],
      "metadata": {
        "id": "54dfhVHl-ln4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=outputs.to(device)"
      ],
      "metadata": {
        "id": "iahTu9MVZAWn"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "id": "BlwUoihOOGgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c3f63d-aecf-4572-d8d7-8601c93b88ac"
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9960, -1.4255, -0.9409],\n",
            "        [-1.0602, -1.3814, -0.9104],\n",
            "        [-0.9231, -1.4759, -0.9831],\n",
            "        [-0.9460, -1.4035, -1.0052],\n",
            "        [-1.0492, -1.3077, -0.9693],\n",
            "        [-1.0200, -1.3869, -0.9427],\n",
            "        [-0.9937, -1.4267, -0.9424],\n",
            "        [-0.9383, -1.4846, -0.9620],\n",
            "        [-0.9346, -1.4270, -1.0018],\n",
            "        [-0.9385, -1.4689, -0.9713],\n",
            "        [-0.9775, -1.3594, -1.0026],\n",
            "        [-0.9670, -1.4080, -0.9805],\n",
            "        [-0.9592, -1.3678, -1.0157],\n",
            "        [-0.9903, -1.3783, -0.9767],\n",
            "        [-1.0310, -1.3777, -0.9386],\n",
            "        [-0.9318, -1.4225, -1.0078],\n",
            "        [-1.0117, -1.4004, -0.9418],\n",
            "        [-0.9724, -1.4194, -0.9677],\n",
            "        [-1.0077, -1.3191, -1.0008],\n",
            "        [-1.1239, -1.2910, -0.9163],\n",
            "        [-0.9806, -1.3769, -0.9874],\n",
            "        [-1.0778, -1.4138, -0.8760],\n",
            "        [-0.9843, -1.4388, -0.9440],\n",
            "        [-1.0237, -1.4379, -0.9080],\n",
            "        [-0.9024, -1.4935, -0.9948],\n",
            "        [-1.0459, -1.4401, -0.8874],\n",
            "        [-0.9492, -1.4018, -1.0030],\n",
            "        [-0.8851, -1.4884, -1.0172],\n",
            "        [-0.9620, -1.4861, -0.9375],\n",
            "        [-0.9383, -1.4286, -0.9968],\n",
            "        [-0.9473, -1.4407, -0.9797],\n",
            "        [-1.0908, -1.3356, -0.9136],\n",
            "        [-1.0898, -1.3512, -0.9043],\n",
            "        [-0.9546, -1.4741, -0.9518],\n",
            "        [-1.0250, -1.3957, -0.9325],\n",
            "        [-0.9580, -1.4118, -0.9872],\n",
            "        [-1.0212, -1.2985, -1.0027],\n",
            "        [-1.0807, -1.3390, -0.9200],\n",
            "        [-1.0069, -1.3805, -0.9592],\n",
            "        [-0.9301, -1.4883, -0.9683],\n",
            "        [-1.0115, -1.3251, -0.9927],\n",
            "        [-0.9517, -1.4319, -0.9807],\n",
            "        [-0.9659, -1.3798, -1.0004],\n",
            "        [-0.8912, -1.5049, -1.0002],\n",
            "        [-0.9809, -1.3245, -1.0241],\n",
            "        [-0.9120, -1.4271, -1.0265],\n",
            "        [-0.9053, -1.4309, -1.0314],\n",
            "        [-0.9825, -1.3631, -0.9949],\n",
            "        [-0.9912, -1.4685, -0.9198],\n",
            "        [-0.9859, -1.4011, -0.9660],\n",
            "        [-1.0054, -1.3767, -0.9631],\n",
            "        [-0.9299, -1.3908, -1.0312],\n",
            "        [-0.8797, -1.5794, -0.9702],\n",
            "        [-1.0011, -1.3644, -0.9755],\n",
            "        [-0.9722, -1.3923, -0.9855],\n",
            "        [-0.9424, -1.5133, -0.9413],\n",
            "        [-0.9472, -1.4304, -0.9863],\n",
            "        [-0.9978, -1.4733, -0.9109],\n",
            "        [-0.9955, -1.4294, -0.9391],\n",
            "        [-1.0084, -1.3631, -0.9694],\n",
            "        [-0.9013, -1.5595, -0.9578],\n",
            "        [-0.9298, -1.4683, -0.9807],\n",
            "        [-1.0009, -1.3300, -0.9997],\n",
            "        [-0.9346, -1.5115, -0.9502]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now that we have defined the model arcitecture, let's see how many trainable parameters we have.\n",
        "- numel() returns the total number of elemtns in input tensor. \n",
        "- If we would have trained the parameters in BERT pretrained model, then this number of trainable parameters would have been in millions."
      ],
      "metadata": {
        "id": "QHIlgh0gWUS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no. of trainable parameters\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "metadata": {
        "id": "6slkc64hOHGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd0097f-4333-4734-ab5d-357160463645"
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Optimizer and Loss\n",
        "\n"
      ],
      "metadata": {
        "id": "TNmXN8aCXKIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optmizer\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.0005)"
      ],
      "metadata": {
        "id": "FEPc9UNGOHOw"
      },
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understnding class distribution\n",
        "\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bar chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "d74YovTcXUKJ",
        "outputId": "6291b53c-79d8-4bd0-a07d-1d26eddf8b51"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 486
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library for array processing\n",
        "import numpy as np\n",
        "\n",
        "# computing the class weights\n",
        "class_weights=compute_class_weight(class_weight='balanced',classes=np.unique(labels),y=labels)\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks7eGznVXUko",
        "outputId": "a0c59739-166b-423f-e7d1-b4ca7b942d2e"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.53170625 1.57470152 2.06517139]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a list of class weights into a tensor\n",
        "weights=torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# transferring weights to GPU\n",
        "weights=weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy=nn.NLLLoss(weight=weights)"
      ],
      "metadata": {
        "id": "o41P488pXUty"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the loss\n",
        "print(target)\n",
        "#print(outputs)\n",
        "loss=cross_entropy(outputs,target)\n",
        "print('Loss: ',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AkEekSgXU5M",
        "outputId": "39d6765e-2cbd-472c-e9d4-167ac9041796"
      },
      "execution_count": 489,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 0, 2, 1, 2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 2, 1, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss:  tensor(1.0889, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for computing time in hh:mm:ss\n",
        "\n",
        "def format_time(elapsed):\n",
        "\n",
        "  elapsed_rounded=int(round(elapsed))\n",
        "\n",
        "  # format intp hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "59j5udXHaMBP"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches. \n",
        "\n",
        "- During **Training Phase**, for each batch, we need to take following steps:\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropogate Loss\n",
        "4. Update Weights\n",
        "\n",
        "- In **Evaluation Phase**, for each batch, we need to perform following steps:\n",
        "1. Perform forward pass\n",
        "2. Compute Loss\n",
        "\n",
        "**Training: Epoch -> Batch -> Forward Pass -> Compute Loss -> Backpropogate Loss -> Update Weights**\n",
        "\n",
        "\n",
        "**Evaluation: Epoch -> Batch -> Forward Pass -> Compute Loss**\n",
        "\n",
        "**Epoch**\n",
        "- An epoch refers to one complete pass of the training dataset through the algorithm (through the neural network)\n",
        "- Number of epochs is the number of complete passes of the entire training dataset passing through the training or learning process of the algorithm.\n",
        "- It is the hyper parameter that indicates number of times the learning algorithm will work through the entire dataset."
      ],
      "metadata": {
        "id": "40cusuH50SV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Phase**\n",
        "\n",
        "For each epoch, we have a training phase and validation phase. Hence, for each batch, we need to take following steps:\n",
        "  1. Load data ontp the GPU for acceleration\n",
        "  2. Unpack the data inputs and labels\n",
        "  3. Clear out the gradients calculated in previous steps\n",
        "  4. Forward pass (feed input data through week)\n",
        "  5. Backward pass (backpropogation)\n",
        "  6. Update parameters using optimizer.step()\n",
        "  7. Track variables for monitoring progress"
      ],
      "metadata": {
        "id": "reNg_9ZY1-2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a training function for the model:\n",
        "\n",
        "def train():\n",
        "  print('\\n Training')\n",
        "\n",
        "  # set the model on training phase- Dropout layers are activated\n",
        "  model.train()\n",
        "  # recording current time\n",
        "  t0=time.time()\n",
        "  # initialize the loss and accuracy to 0\n",
        "  total_loss,total_accuracy=0,0\n",
        "\n",
        "  # Create an empty list to save the model prediction\n",
        "  total_preds=[]\n",
        "\n",
        "  # for every batch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    #Progress update after every 40 batches\n",
        "    if step % 40==0 and not step==0:\n",
        "      elapsed=format_time(time.time()-t0)         # Calculate elapsed time in minutes\n",
        "      print(' Batch{:>5,} of {:>5,}. Elapsed: {:}.'.format(step,len(train_dataloader),elapsed)) # Print progress\n",
        "    batch=tuple(t.to(device) for t in batch)      # push the batch to GPU\n",
        "\n",
        "    # batch is a part of all the records in train_dataloader. It contains 3 pytorch tensors:\n",
        "    # [0]: input ids\n",
        "    # [1]: attention masks\n",
        "    # [2]: labels\n",
        "\n",
        "    sent_id,mask,labels=batch\n",
        "\n",
        "    #Pytorch doesn't automatically clear previously calculated gradients, hence before performing a backward pass, clear previous gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds=model(sent_id,mask)\n",
        "\n",
        "    # Compute the loss between actual and predicted values\n",
        "    loss=cross_entropy(preds,labels)\n",
        "\n",
        "    #Accumulate training loss over all the batches, so that we can calculate the average loss at the end\n",
        "    # loss is a tensor containing a single value.\n",
        "    # .itme() method just returns the Python value from the tensor\n",
        "\n",
        "    total_loss=total_loss+loss.item()\n",
        "\n",
        "    # Perform backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "    # During backward pass, information about parameter changes flows backwards, from the output to the hidden layers to the input\n",
        "\n",
        "    optimizer.step() \n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # Here, the optimizer dictates the update rule = how the parameters are modified based on their gradients, learning rate and so on.\n",
        "\n",
        "    # The model predictions are stored on GPU, so push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # Accumulate model predicitons of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  \n",
        "\n",
        "    # Compute the training loss of an epoch\n",
        "  avg_loss=total_loss/len(train_dataloader)\n",
        "\n",
        "  # The prediction are in the form of (no. of batches, size of batch, no. of classes)\n",
        "  # So we need to resahpe the predictions in the form of number of samples x number of classes\n",
        "\n",
        "  total_preds=np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss,total_preds"
      ],
      "metadata": {
        "id": "KrPatVOO0GQX"
      },
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "2. Unpack the data inputs\n",
        "3. Forward Pass\n",
        "4. Compute Loss on validation data]\n",
        "5. Track variables for monitoring"
      ],
      "metadata": {
        "id": "RsXNo63cC3cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for evaluating the model\n",
        "\n",
        "def evaluate():\n",
        "  print(\"'n Evaluating....\")\n",
        "\n",
        "  # set the model on validation phase. Here dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  # record the current time\n",
        "  t0=time.time()\n",
        "\n",
        "  # initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy=0,0\n",
        "\n",
        "  # Create an empty list to save model predicitons\n",
        "  total_preds=[]\n",
        "\n",
        "  # for each batch\n",
        "\n",
        "  for step, batch in enumerate(validation_dataloader):\n",
        "    if step%40==0 and not step ==0:\n",
        "      elapsed=format_time(time.time()-t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "    \n",
        "    batch=tuple(t.to(device) for t in batch)\n",
        "    sent_id,mask,labels=batch\n",
        "      \n",
        "    #deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      preds=model(sent_id,mask)\n",
        "      loss=cross_entropy(preds,labels)\n",
        "      total_loss=total_loss+loss.item()\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "    \n",
        "    avg_loss=total_loss/len(validation_dataloader)\n",
        "\n",
        "    total_preds=np.concatenate(total_preds,axis=0)\n",
        "\n",
        "    return avg_loss,total_preds\n"
      ],
      "metadata": {
        "id": "DAwqa5VE0Gdu"
      },
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.      \n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "SoV18Cx4JS9G"
      },
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Train the model\n"
      ],
      "metadata": {
        "id": "cOSVHUq3E2yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the initial loss to infinite\n",
        "best_valid_loss=float('inf')\n",
        "\n",
        "# Create an empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs=5\n",
        "\n",
        "#for each epoch repeat call the train() method\n",
        "for epoch in range(epochs):\n",
        "  print('\\n ............epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "\n",
        "  #train model\n",
        "  train_loss,_ =train()\n",
        "\n",
        "  #evaluate model\n",
        "  valid_loss,_=evaluate()\n",
        "\n",
        "  # save the best model\n",
        "  if valid_loss<best_valid_loss:\n",
        "    best_valid_loss=valid_loss\n",
        "    torch.save(model.state_dict(),'Saved_weights.pt')\n",
        "\n",
        "  # Accumulate training and validaion loss\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "\n",
        "  print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "  print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeLLAOsE0Gs5",
        "outputId": "3a91ab9e-177a-4b3e-dbc5-cf78679be2ee"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ............epoch 1 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   206. Elapsed: 0:00:04.\n",
            " Batch   80 of   206. Elapsed: 0:00:08.\n",
            " Batch  120 of   206. Elapsed: 0:00:13.\n",
            " Batch  160 of   206. Elapsed: 0:00:17.\n",
            " Batch  200 of   206. Elapsed: 0:00:21.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.716\n",
            "Validation Loss: 0.746\n",
            "\n",
            " ............epoch 2 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   206. Elapsed: 0:00:04.\n",
            " Batch   80 of   206. Elapsed: 0:00:09.\n",
            " Batch  120 of   206. Elapsed: 0:00:13.\n",
            " Batch  160 of   206. Elapsed: 0:00:18.\n",
            " Batch  200 of   206. Elapsed: 0:00:22.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.716\n",
            "Validation Loss: 0.701\n",
            "\n",
            " ............epoch 3 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   206. Elapsed: 0:00:05.\n",
            " Batch   80 of   206. Elapsed: 0:00:09.\n",
            " Batch  120 of   206. Elapsed: 0:00:14.\n",
            " Batch  160 of   206. Elapsed: 0:00:19.\n",
            " Batch  200 of   206. Elapsed: 0:00:24.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.709\n",
            "Validation Loss: 0.656\n",
            "\n",
            " ............epoch 4 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   206. Elapsed: 0:00:05.\n",
            " Batch   80 of   206. Elapsed: 0:00:09.\n",
            " Batch  120 of   206. Elapsed: 0:00:14.\n",
            " Batch  160 of   206. Elapsed: 0:00:18.\n",
            " Batch  200 of   206. Elapsed: 0:00:23.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.705\n",
            "Validation Loss: 0.645\n",
            "\n",
            " ............epoch 5 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   206. Elapsed: 0:00:04.\n",
            " Batch   80 of   206. Elapsed: 0:00:09.\n",
            " Batch  120 of   206. Elapsed: 0:00:13.\n",
            " Batch  160 of   206. Elapsed: 0:00:18.\n",
            " Batch  200 of   206. Elapsed: 0:00:22.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: 0.705\n",
            "Validation Loss: 0.640\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. Evaluate the model\n",
        "\n"
      ],
      "metadata": {
        "id": "6cvB38dE0tZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # load weights of best model\n",
        "path='Saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93OTP7dz0G72",
        "outputId": "91a1e268-8a9b-4a90-b09d-4f359151de96"
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model prediction on the validation data\n",
        "valid_loss, preds=evaluate()\n",
        "# this returns 2 elements- Validation loss and prediction\n",
        "print(valid_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlpvSgFD0oss",
        "outputId": "59a81c74-8e0f-43dc-b37a-805c61e7e090"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "0.6396074994750645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the log(probabilities) into class & then choosing index of maximum value as class\n",
        "y_pred=np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true=validation_labels"
      ],
      "metadata": {
        "id": "xsj5m4XF0o_s"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true,y_pred))"
      ],
      "metadata": {
        "id": "YbLTtyJ90pIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb86585e-fd66-4ffc-fe74-c21f540f60be"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.66      0.78       918\n",
            "           1       0.49      0.70      0.58       310\n",
            "           2       0.56      0.89      0.69       236\n",
            "\n",
            "    accuracy                           0.71      1464\n",
            "   macro avg       0.66      0.75      0.68      1464\n",
            "weighted avg       0.78      0.71      0.72      1464\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max Length = 28 | Batch Size = 64 | Learning Rate = 0.0005 | Accuracy = 0.76 | This model is good to identify 0's (Negatives) and 2's (Positives) but for 1's (Neutrals) f1-score (0.48) and recall(0.38) are not so good.\n",
        "\n",
        "Max Length = 28 | Batch Size = 64 | Learning Rate = 0.001 | Accuracy = 0.74 | This model is a good choice as f1-score for Negatives is 0.81, for Neutral it is 0.59 and for Positive it is 0.71\n"
      ],
      "metadata": {
        "id": "1SbqkR9el5do"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFygmQsnpF1N"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThWeW9Ko7XRN"
      },
      "execution_count": 497,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "- Analytics Vidhya Coursework\n",
        "\n",
        "- https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
        "\n",
        "- https://www.cs.toronto.edu/~lczhang/360/lec/w03/nn.html\n"
      ],
      "metadata": {
        "id": "G_KO56G37Xrb"
      }
    }
  ]
}